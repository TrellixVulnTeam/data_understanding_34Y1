{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf07c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = [\n",
    "    '_C3_81frica.txt','Aeropuerto.txt','Agricultura.txt','Alan_Turing.txt',\n",
    "    'Antiguo_Egipto.txt','Arte.txt','Asia.txt','Babilonia_(ciudad).txt',\n",
    "    'Biblia.txt','Biodiversidad.txt','Capitalismo.txt','Ciencia.txt','Colombia.txt',\n",
    "    'Consumo.txt','Cristianismo.txt','Cristo.txt','Cultura.txt','Democracia.txt',\n",
    "    'Diccionario.txt','Divina_comedia.txt','Ecologismo.txt','Energ_C3_ADa_nuclear.txt',\n",
    "    'Enrique_VIII_de_Inglaterra.txt','Escritura.txt','Est_C3_A9tica.txt','Estado.txt',\n",
    "    'Estados_Unidos.txt','Europa.txt','Filosof_C3_ADa.txt','Finanzas.txt','Fruta.txt',\n",
    "    'Gabriel_Garc_C3_ADa_M_C3_A1rquez.txt','Gastronom_C3_ADa_de_M_C3_A9xico.txt','George_Patton.txt',\n",
    "    'Grecia.txt','Guerra_Fr_C3_ADa.txt','Henry_Ford.txt','Holocausto.txt','Homo_sapiens.txt',\n",
    "    'Inteligencia_artificial.txt','Italia.txt','Jorge_Isaacs.txt','Juda_C3_ADsmo.txt','Juglar.txt',\n",
    "    'Julio_Garavito.txt','Liberalismo.txt','Libro.txt','Ludwig_van_Beethoven.txt','Nevado_del_Ruiz.txt',\n",
    "    'Nikola_Tesla.txt','Odisea.txt','Organizaci_C3_B3n_de_las_Naciones_Unidas.txt',\n",
    "    'Per_C3_ADodo_helen_C3_ADstico.txt','Pizza.txt','Pueblos_germ_C3_A1nicos.txt','Real_Academia_Espa_C3_B1ola.txt',\n",
    "    'Reino_Unido.txt','Revoluci_C3_B3n_Industrial.txt','Rueda.txt','Salsa_(g_C3_A9nero_musical).txt',\n",
    "    'Saxof_C3_B3n.txt','Segunda_Guerra_Mundial.txt','Sublime.txt','Thomas_Alva_Edison.txt','Valle.txt'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3962db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = open('Estados_Unidos.txt','r',encoding='utf-8')\n",
    "texto = file_test.read()\n",
    "#print(texto)\n",
    "file_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('Estados_Unidos.txt', 'r',encoding='utf-8') as raw_file:\n",
    "\n",
    "  logs_text = raw_file.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab5656d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pingüino: Malñãgà ês uñ̺ã cieeauèdãd fantañstica y èn Logroño me pica el... moñǫ̝̘̦̞̟̩̐̏̋͌ͬ̚͡õ̪͓͍̦̓ơ̤̺̬̯͂̌͐͐͟o͎͈̳̠̼̫͂̊\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from unicodedata import normalize\n",
    "\n",
    "s = \"Pingüino: Málñãgà ês uñ̺ã cíééáuèdãd fantáñstica y èn Logroño me pica el... moñǫ̝̘̦̞̟̩̐̏̋͌́ͬ̚͡õ̪͓͍̦̓ơ̤̺̬̯͂̌͐͐͟o͎͈̳̠̼̫͂̊\"\n",
    "\n",
    "# -> NFD y eliminar diacríticos\n",
    "s = re.sub(\n",
    "        r\"([^\\u0301])[\\u0301]\", r\"\\1\", \n",
    "        normalize( \"NFD\", s)\n",
    "        #r\"([^n\\u0300-\\u036f]|n(?!\\u0303(?![\\u0300-\\u036f])))[\\u0300-\\u036f]+\", r\"\\1\", \n",
    "    )\n",
    "\n",
    "# -> NFC\n",
    "s = normalize( 'NFC', s)\n",
    "\n",
    "print( s )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c72921",
   "metadata": {},
   "source": [
    "unicodedata.normalize(form, unistr)\n",
    "Return the normal form form for the Unicode string unistr. Valid values for form are ‘NFC’, ‘NFKC’, ‘NFD’, and ‘NFKD’.\n",
    "\n",
    "The Unicode standard defines various normalization forms of a Unicode string, based on the definition of canonical equivalence and compatibility equivalence. In Unicode, several characters can be expressed in various way. For example, the character U+00C7 (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as the sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1ac6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c2d40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ¿Cómo puedo reemplazar las letras con tildes por las mismas sin tilde, pero no la “ñ”?\n",
    "#  https://es.stackoverflow.com/q/135707/127\n",
    "\n",
    "\n",
    "print(logs_text[:100])\n",
    "from unicodedata import normalize\n",
    "# -> NFD y eliminar diacríticos\n",
    "remove_diacriticals = re.sub(r\"([^\\u0301])[\\u0301]\",r\"\\1\", \n",
    "        normalize( \"NFD\", logs_text), 0, re.I\n",
    "        )\n",
    "remove_diacriticals = normalize( 'NFC', remove_diacriticals)\n",
    "print(remove_diacriticals[:100])\n",
    "##\n",
    "remove_symbols = re.sub(r'[^\\w^n\\u0303|\\s]|_', ' ', remove_diacriticals)\n",
    "print(remove_symbols[:100])\n",
    "##\n",
    "only_letters = re.sub(r\"\\S*[^a-zñA-ZÑ\\s]\\S*\", \"\", remove_symbols)\n",
    "print(only_letters[:100])\n",
    "##\n",
    "def doble_upper(match_obj):\n",
    "    char_elem = match_obj.group(0)\n",
    "    count = 0\n",
    "    for letter in char_elem:\n",
    "        if letter.isupper():\n",
    "            count +=1\n",
    "        if count >= 2:\n",
    "            return \"\"\n",
    "            break\n",
    "    return char_elem\n",
    "remove_acronyms = re.sub(r\"\\S*\\w\\S*\", doble_upper, only_letters)\n",
    "print(remove_acronyms[:100])\n",
    "##----------------\n",
    "def reverse_case(match_obj):\n",
    "    char_elem = match_obj.group(0)\n",
    "    return char_elem.lower()\n",
    "\n",
    "remove_uppercase = re.sub(r\"([A-ZÑ])\",reverse_case, remove_acronyms)\n",
    "print(remove_uppercase[:100] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02facb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = re.sub(\"[^\\w|^n\\u0303]\", \" \",remove_uppercase).split()\n",
    "#print(list_of_words[:100])\n",
    "list_large_words=[]\n",
    "for word in list_of_words:\n",
    "    #print(word)\n",
    "    #print(len('año'))\n",
    "    if len(word)>3:\n",
    "        #print(len(word))\n",
    "        list_large_words.append(word)\n",
    "#print(len(list_large_words))\n",
    "#print(list_large_words[:100])\n",
    "#print(len('año'))\n",
    "# -> NFC\n",
    "#logs_text = normalize( 'NFC', logs_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "print(\"\\n-------------------------------------------------------------------\\n\")\n",
    "stop_words = stopwords.words('spanish')\n",
    "list_filter_words = []\n",
    "\n",
    "for word in list_large_words:\n",
    "    if word not in stop_words:\n",
    "        list_filter_words.append(word)\n",
    "print(list_filter_words[:100])\n",
    "print(len(list_filter_words))\n",
    "##\n",
    "data_base_filter = open(\"Data_Base_Words_Filter.txt\", \"a\")\n",
    "\n",
    "\n",
    "list_final_words = []\n",
    "for word in list_filter_words:\n",
    "    if word not in list_final_words:\n",
    "        list_final_words.append(word)\n",
    "##\n",
    "for word in list_filter_words:\n",
    "    data_base_filter.write(word)\n",
    "    data_base_filter.write(' ')\n",
    "data_base_filter.close()  \n",
    "##\n",
    "data_base_final = open(\"Data_Base_Final_Words.txt\", \"a\")\n",
    "\n",
    "print(list_final_words[:100])\n",
    "print(len(list_final_words))\n",
    "\n",
    "for word in list_final_words:\n",
    "    data_base_final.write(word)\n",
    "    data_base_final.write(' ')\n",
    "data_base_final.close()       \n",
    "print('estados' in list_filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bf41dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214183\n",
      "32295\n",
      "nicenoconstantinopolitano\n"
     ]
    }
   ],
   "source": [
    "with open(\"Data_Base_Words_Filter.txt\", 'r') as raw_file:\n",
    "\n",
    "  logs_text = raw_file.read()\n",
    "\n",
    "#print(logs_text)\n",
    "words_filter_list = re.sub(\"[\\s]\", \" \",logs_text).split()\n",
    "print(len(words_filter_list))\n",
    "\n",
    "with open(\"Data_Base_Final_Words.txt\", 'r') as raw_file:\n",
    "\n",
    "  logs_text = raw_file.read()\n",
    "\n",
    "#print(logs_text)\n",
    "words_final_list = re.sub(\"[\\s]\", \" \",logs_text).split()\n",
    "print(len(words_final_list))\n",
    "print (max(words_final_list,key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c1bf066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35816\n",
      "27\n",
      "4633\n",
      "[35816, 4633, 14706, 11720, 27382, 3064, 4381, 2408, 25951, 1079, 746, 11313, 8111, 20148, 280, 25293, 6815, 619, 21284, 19464, 14916, 7937, 3378, 366, 724, 818, 1638]\n"
     ]
    }
   ],
   "source": [
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', \n",
    "            'n','ñ', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "#print(words_final_list)\n",
    "def position_dict(letters_list,words_list):\n",
    "    dicts = {}\n",
    "    for letter in letters_list:\n",
    "        for word in words_list:\n",
    "            #print(word)\n",
    "            for letter1 in word:\n",
    "                if letter == letter1:\n",
    "                    if letter not in dicts:\n",
    "                        dicts[letter] = []\n",
    "                    dicts[letter].append(word.index(letter1)+1)\n",
    "    return dicts\n",
    "word = words_final_list[1]\n",
    "position_letters_dict = position_dict(alphabet,words_final_list)\n",
    "\n",
    "\n",
    "print(len(position_letters_dict['a']))\n",
    "print(len(position_letters_dict))\n",
    "print(len(position_letters_dict['b']))\n",
    "list_letter_repetitions=[]\n",
    "for j in position_letters_dict:\n",
    "    list_letter_repetitions.append(len(position_letters_dict[j]))\n",
    "\n",
    "print(list_letter_repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st\n",
    "def list_dict_data(parameter,dictionary):\n",
    "    b= (max(dictionary[parameter]))\n",
    "    list_dict=(dictionary[parameter])\n",
    "    position_sum=[0 for i in range(b+1)]\n",
    "    #print(list_dict)\n",
    "    for j in list_dict:\n",
    "        #print(j)\n",
    "        position_sum[j] += 1\n",
    "    del position_sum[0]\n",
    "    Q1 = np.percentile(dictionary[parameter], 25)\n",
    "    Q2 = np.percentile(dictionary[parameter], 50)\n",
    "    Q3 = np.percentile(dictionary[parameter], 75)\n",
    "    P99 = np.percentile(dictionary[parameter], 99)\n",
    "    median = np.median(dictionary[parameter])\n",
    "    mode = st.mode(dictionary[parameter])\n",
    "    mean = np.mean(dictionary[parameter])\n",
    "    return [position_sum,Q1,Q2,Q3,median,mode,mean,P99,parameter]\n",
    "positions= list_dict_data('e',position_letters_dict)\n",
    "print(positions[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09364484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# create a dataset\n",
    "height = positions[0]\n",
    "bars = [i+1 for i in range(len(positions[0]))]\n",
    "x_pos = np.arange(len(bars))\n",
    "\n",
    "# Create bars\n",
    "plt.bar(x_pos, height, color=(0.2, 0.4, 0.6, 0.6))\n",
    "\n",
    "# Create names on the x-axis\n",
    "plt.xticks(x_pos, bars)\n",
    "plt.axvline(positions[1]-1,color = 'b',label = 'Q1')\n",
    "plt.axvline(positions[2]-1,color = 'g',label = 'Q2')\n",
    "plt.axvline(positions[3]-1,color = 'y',label = 'Q3')\n",
    "plt.axvline(positions[7]-1,color = 'r',label = 'P99')\n",
    "# Show graph\n",
    "plt.title('Diagrama de barras - posición letra \"{}\"'.format('a'))\n",
    "plt.xlabel('Posicion')\n",
    "plt.ylabel('Repeticiones')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('La mediana de la posicion es: {}'.format(positions[4]))\n",
    "print('La moda de la posicion es: {}'.format(positions[5]))\n",
    "print('La media de la posicion es: {}'.format(positions[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088be36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize = (9,5))\n",
    "plt.title('Grafico caja y bigotes')\n",
    "sns.boxplot(position_letters_dict[positions[8]])\n",
    "\n",
    "plt.ylabel('Repeticiones')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_words = []\n",
    "for word in words_final_list:\n",
    "    cont = 0\n",
    "    for word2 in words_filter_list:\n",
    "        if word == word2:\n",
    "            cont += 1\n",
    "    frequency_words.append(cont)\n",
    "\n",
    "#print(frequency_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc8880d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
